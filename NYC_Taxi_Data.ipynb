{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import vaex\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to read\n",
    "columns = ['Total_amount', 'Dropoff_longitude', 'Passenger_count', 'VendorID', 'Extra', \n",
    "           'Tip_amount','Pickup_longitude', 'Store_and_fwd_flag', 'Payment_type',\n",
    "           'MTA_tax', 'Fare_amount', 'Pickup_latitude', 'Dropoff_latitude', 'Tolls_amount',\n",
    "           'Trip_distance', 'Improvement_surcharge', 'RateCodeID', 'tpep_dropoff_datetime', \n",
    "           'tpep_pickup_datetime']\n",
    "\n",
    "# Force dtypes for these columns - some choices are made to optimize\n",
    "dtypes = {\n",
    "'VendorID': np.int32,\n",
    "'tpep_pickup_datetime': np.int16,\n",
    "'tpep_dropoff_datetime': np.int16,\n",
    "'Passenger_count': np.int16,\n",
    "'Trip_distance': np.int16,\n",
    "'Pickup_longitude': np.int32,\n",
    "'Pickup_latitude': np.int32,\n",
    "'RateCodeID': np.int32,\n",
    "'Store_and_fwd_flag': np.int16,\n",
    "'Dropoff_longitude': np.int32,\n",
    "'Dropoff_latitude': np.int32,\n",
    "'Payment_type': np.object,\n",
    "'Fare_amount': np.int8,\n",
    "'Extra': np.int8,\n",
    "'MTA_tax': np.int8,\n",
    "'Improvement_surcharge': np.int8,\n",
    "'Tip_amount': np.int8,\n",
    "'Tolls_amount': np.int8,\n",
    "'Total_amount': np.int8,    \n",
    "}\n",
    "\n",
    "# Setup renaming dictionary\n",
    "rename_dict = {\n",
    "        'tpep_pickup_datetime' : 'PickupDateTime',\n",
    "        'tpep_dropoff_datetime': 'DropoffDateTime',\n",
    "        'Passenger_count': 'Passenger#',\n",
    "        'Pickup_longitude' : 'PickupLong',\n",
    "        'Pickup_latitude': 'Pickuplat',\n",
    "        'Dropoff_longitude': 'DropoffLong',\n",
    "        'Dropoff_latitude': 'DropoffLat',\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the list of zip files to be opened and converted\n",
    "zip_list = np.sort(np.array(glob.glob('yellowtd_2009_1.zip')))[::-1]\n",
    "\n",
    "# The output directory\n",
    "output_dir = './yellowtd_2009_1/hdf5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a4fd8777fe6d>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for file in tqdm(zip_list, leave=False, desc='Converting csv to hdf5..'):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Converting csv to hdf5..'), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The magic happens here:\n",
    "for file in tqdm(zip_list, leave=False, desc='Converting csv to hdf5..'):\n",
    "    # Setting up the files, and directories\n",
    "    zip_file = ZipFile(file)\n",
    "    output_file = file.split('/')[-1][:-3] + 'hdf5'\n",
    "    output = output_dir + output_file\n",
    "    \n",
    "    # Check if a converted file already exists: if it does then skip it,\n",
    "    if (os.path.exists(output) and os.path.isfile(output)):\n",
    "        pass\n",
    "    else:\n",
    "        # Importing the data into pandas\n",
    "        pandas_df = [pd.read_csv(zip_file.open(text_file.filename),\n",
    "                                 encoding='latin',\n",
    "                                 usecols=None,\n",
    "                                 dtype=dtypes,)\n",
    "                    for text_file in zip_file.infolist()\n",
    "                    if text_file.filename.endswith('.csv')][0]\n",
    "        # Rename some columns to match the more well known dataset from\n",
    "        # http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "        pandas_df.rename(columns=rename_dict, inplace=True)\n",
    "                 \n",
    "        # Importing the data from pandas to vaex\n",
    "        vaex_df = vaex.from_pandas(pandas_df, copy_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import vaex\n",
    "import numpy as np\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except:\n",
    "        return s\n",
    "    \n",
    "def alphanum_key(s):\n",
    "    \"\"\"Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_list = glob.glob('./yellowtd_2009_1/hdf5/')\n",
    "hdf5_list.sort(key=alphanum_key)\n",
    "hdf5_list = np.array(hdf5_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-112d973eb716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This is an important step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmaster_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf5_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# exporting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmaster_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./yellowtd_2009_1/hdf5/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/vaex/__init__.py\u001b[0m in \u001b[0;36mopen_many\u001b[0;34m(filenames)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"#\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvaex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrameConcatenated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/vaex/dataframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dfs, name)\u001b[0m\n\u001b[1;32m   5975\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5976\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5977\u001b[0;31m         \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5978\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvirtual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvirtual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# This is an important step\n",
    "master_df = vaex.open_many(hdf5_list)\n",
    "\n",
    "# exporting\n",
    "master_df.export_hdf5(path='./yellowtd_2009_1/hdf5/', progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
